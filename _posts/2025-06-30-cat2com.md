---
title: "Category Theory, Abstraction and Computer Science"
date: 2025-06-30
---

I am by training a computer scientist. One of the things I find most fascinating about computer science is its reliance on layers of abstraction. Much of what we do with computers is built upon carefully hidden complexity. When you run a word processor, for instance, you simply tap an icon, and a window appears. You interact with menus, buttons, and icons, rarely stopping to consider what lies beneath.

But behind that user interface are pixels—just colored dots on a screen—that visually represent program logic. That logic is itself encoded in software: programs that appear to us as applications, but are in fact binary sequences of 0s and 1s. These sequences are not arbitrary; they carry meaning specific to the architecture of the computer on which they run. Whether it’s a laptop, a smartphone, or a server, each interprets that binary differently, but all follow the same principle: abstraction.

Even at this level, abstraction has already begun. We often forget that computers are fundamentally electronic machines. They operate through electric flows, with binary digits representing the **ON** and **OFF** states of electric current. These states correspond to the physical behavior of transistors—tiny switches that form the foundation of all computing hardware. A computer program, then, is ultimately just a highly structured set of instructions that controls the ON/OFF patterns of billions of switches, based on inputs like keyboard strokes and mouse clicks.

But this begs a deeper question: How can such electronic switching give rise to something as sophisticated as a word processor or even a programming language?

To answer that, we must go back almost a century, to a time when mathematicians began asking a profound question:

**Can all problems be solved algorithmically?**

Surprisingly, the answer is  **no** .

But while the answer itself is sobering, the journey that led to this conclusion is full of rich ideas—and it is here that abstraction reaches one of its highest forms.

### Formalization of Mathematics

The story begins in the early twentieth century, a time when many mathematicians believed they could formalize all the mathematics. But what does formalization actually mean?

Think back to high school geometry—specifically, Euclidean geometry. You might recall that this entire system is built upon just a few basic assumptions, known as Euclid’s postulates. There are five of them:

1. A straight line segment can be drawn joining any two points.
2. A straight line segment can be extended indefinitely in both directions.
3. A circle can be drawn with any center and any radius.
4. All right angles are equal to one another.
5. If two lines are drawn such that a third line crossing them forms interior angles on the same side that sum to less than two right angles, then the two lines will eventually intersect on that side (this is the parallel postulate).
From these five seemingly simple rules, Euclidean geometry unfolds. Every theorem, every construction in this system follows logically from these axioms.

This is the power of formalization: you start with a small set of precise, foundational rules, and then derive everything else through logical deduction. So naturally, mathematicians wondered—can we do the same for all the mathematics?

That’s what Bertrand Russell and Alfred North Whitehead tried to do in their massive work Principia Mathematica. Their goal was to find a complete, formal foundation for all of mathematics built from logic alone. The title of their work was a deliberate echo of Newton’s Principia, a nod to their desire to give mathematics a similarly rigorous grounding.

But this grand vision was soon interrupted.

A young mathematician named Kurt Gödel published a result in 1931 that shook the foundations of this pursuit: the incompleteness theorems. Gödel proved that in any sufficiently expressive formal system—one powerful enough to include arithmetic—there exist true mathematical statements that cannot be proven from within that system.

In other words, some truths can’t be reached through logic alone. This result showed that no formal system can be both complete and consistent.

It was a turning point. The idea of reducing all mathematical truth to logic suddenly seemed not just difficult, but impossible.

To visualize this chapter of intellectual history, the graphic novel Logicomix offers a beautifully illustrated account of Gödel’s work and its impact. His theorems didn’t just challenge mathematical certainty—they revealed the limits of abstraction and logic themselves.

But at the same time, these limits opened new doors—leading to new ways of thinking about computation, formal systems, and abstraction. One path led to the birth of computer science. Another, to the rise of category theory.

Would you like the next section to move into Turing’s response to Hilbert’s questions, and the origin of computational models?

To be continued..
